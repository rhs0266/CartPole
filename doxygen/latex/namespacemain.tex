\hypertarget{namespacemain}{}\section{main nosaukumvietas apraksts}
\label{namespacemain}\index{main@{main}}
\subsection*{Mainīgie}
\begin{DoxyCompactItemize}
\item 
string \hyperlink{namespacemain_a3c06d4083f03655f07172e4ef8e464bf}{O\+U\+T\+\_\+\+D\+IR} = \textquotesingle{}cartpole-\/experiment\textquotesingle{}
\item 
\hyperlink{namespacemain_ac0a261283849e9420511602bb168f4fa}{ddpg} = \hyperlink{classddpg_1_1_d_d_p_g}{D\+D\+PG}()
\end{DoxyCompactItemize}


\subsection{Detalizēts apraksts}
\begin{DoxyVerb}Actor-Critic with continuous action using TD-error as the Advantage, Reinforcement Learning.

The Pendulum example (based on https://github.com/dennybritz/reinforcement-learning/blob/master/PolicyGradient/Continuous%20MountainCar%20Actor%20Critic%20Solution.ipynb)

Cannot converge!!! oscillate!!!

View more on my tutorial page: https://morvanzhou.github.io/tutorials/

Using:
tensorflow r1.3
gym 0.8.0
\end{DoxyVerb}
 

\subsection{Mainīgo dokumentācija}
\index{main@{main}!ddpg@{ddpg}}
\index{ddpg@{ddpg}!main@{main}}
\subsubsection[{\texorpdfstring{ddpg}{ddpg}}]{\setlength{\rightskip}{0pt plus 5cm}main.\+ddpg = {\bf D\+D\+PG}()}\hypertarget{namespacemain_ac0a261283849e9420511602bb168f4fa}{}\label{namespacemain_ac0a261283849e9420511602bb168f4fa}


Definēts līnijā 24 failā main.\+py.

\index{main@{main}!O\+U\+T\+\_\+\+D\+IR@{O\+U\+T\+\_\+\+D\+IR}}
\index{O\+U\+T\+\_\+\+D\+IR@{O\+U\+T\+\_\+\+D\+IR}!main@{main}}
\subsubsection[{\texorpdfstring{O\+U\+T\+\_\+\+D\+IR}{OUT_DIR}}]{\setlength{\rightskip}{0pt plus 5cm}string main.\+O\+U\+T\+\_\+\+D\+IR = \textquotesingle{}cartpole-\/experiment\textquotesingle{}}\hypertarget{namespacemain_a3c06d4083f03655f07172e4ef8e464bf}{}\label{namespacemain_a3c06d4083f03655f07172e4ef8e464bf}


Definēts līnijā 18 failā main.\+py.

